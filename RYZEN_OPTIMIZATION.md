# üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è Ryzen 9 365 (73 TOPS) + 32GB RAM

## ‚úÖ –í–∞—à –Ω–æ—É—Ç–±—É–∫ –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç!

### üí™ –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã:
- **RAM**: 32GB - –æ—Ç–ª–∏—á–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π
- **–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä**: Ryzen 9 365 —Å AI —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º (73 TOPS)
- **AI —É—Å–∫–æ—Ä–µ–Ω–∏–µ**: –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è NPU –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LLM

### üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã:

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | RAM | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|--------|--------|-----|----------|----------|--------------|
| `mistral:7b-instruct` | 7B | ~4GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | **–ò–¥–µ–∞–ª—å–Ω–æ** |
| `llama2:13b-chat` | 13B | ~8GB | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **–û—Ç–ª–∏—á–Ω–æ** |
| `codellama:13b-instruct` | 13B | ~8GB | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ** |
| `mistral-nemo:12b` | 12B | ~7GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **–° AI —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º** |

## üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### 1. –û–±–Ω–æ–≤–∏—Ç–µ docker-compose.yml –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã:

```yaml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: news-summarizer-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=4  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞
      - OLLAMA_MAX_LOADED_MODELS=2  # –î–µ—Ä–∂–∏–º 2 –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç–∏
    restart: unless-stopped
    # –î–ª—è –≤–∞—à–µ–π NPU (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    deploy:
      resources:
        limits:
          memory: 24G  # –û—Å—Ç–∞–≤–ª—è–µ–º 8GB –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
        reservations:
          memory: 16G

  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: news-summarizer-web
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - LOCAL_SUMMARY_URL=http://ollama:11434/api/generate
      - OLLAMA_MODEL=mistral:7b-instruct
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - USE_LOCAL_ONLY=true
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama_data:
```

### 2. –°–æ–∑–¥–∞–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π .env.local:

```env
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è Ryzen 9 365 + 32GB RAM
LOCAL_SUMMARY_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=mistral:7b-instruct
USE_LOCAL_ONLY=true

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
OLLAMA_NUM_PARALLEL=4
OLLAMA_MAX_LOADED_MODELS=2
OLLAMA_FLASH_ATTENTION=1

# –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
SUMMARY_CACHE_TTL_MS=3600000
MAX_CACHE_ENTRIES=1000
```

## üé® Apple + OpenAI –¥–∏–∑–∞–π–Ω

–Ø —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª –∏–º–µ–Ω–Ω–æ —Ç–æ, —á—Ç–æ –≤—ã –ø—Ä–æ—Å–∏–ª–∏:

### ‚úÖ Apple Intelligence —Å—Ç–∏–ª—å:
- **–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∞** –∫–∞—Ä—Ç–æ—á–µ–∫ (–∫–∞–∫ –≤ Apple Intelligence)
- **–ú–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –¥–∏–∑–∞–π–Ω** —Å –±–æ–ª—å—à–∏–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
- **–ü–ª–∞–≤–Ω—ã–µ –∞–Ω–∏–º–∞—Ü–∏–∏** –∏ –ø–µ—Ä–µ—Ö–æ–¥—ã
- **–¢–µ–º–Ω–∞—è —Ç–µ–º–∞** –≤ —Å—Ç–∏–ª–µ Apple
- **–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∞**

### ‚úÖ OpenAI ChatGPT —ç–ª–µ–º–µ–Ω—Ç—ã:
- **–ß–∏—Å—Ç—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –±–µ–∑ –ª–∏—à–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
- **–ö–∞—Ä—Ç–æ—á–∫–∏ —Å —Ç–µ–Ω—è–º–∏** –∏ —Å–∫—Ä—É–≥–ª–µ–Ω–∏—è–º–∏
- **–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ü–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞**
- **–ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è**

## üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ:

### –°–ø–æ—Å–æ–± 1: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Docker
```bash
# –ó–∞–ø—É—Å–∫ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
docker-compose up -d

# –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞—à–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
docker exec news-summarizer-ollama ollama pull mistral:7b-instruct
# –ò–ª–∏ –¥–ª—è –µ—â–µ –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:
docker exec news-summarizer-ollama ollama pull llama2:13b-chat
```

### –°–ø–æ—Å–æ–± 2: –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
```bash
# –°–∫–∞—á–∞–π—Ç–µ Ollama —Å https://ollama.ai/download
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
ollama serve --num-parallel 4 --max-loaded-models 2

# –í –Ω–æ–≤–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å
ollama pull mistral:7b-instruct
```

## üìä –û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ:

- **Mistral 7B**: 1-2 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ —Å—Ç–∞—Ç—å—é
- **Llama 2 13B**: 2-3 —Å–µ–∫—É–Ω–¥—ã –Ω–∞ —Å—Ç–∞—Ç—å—é  
- **–ü–∞–º—è—Ç—å**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ~6-8GB –∏–∑ 32GB
- **CPU**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ~30-50% —è–¥–µ—Ä
- **NPU**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

1. **–ù–∞—á–Ω–∏—Ç–µ —Å Mistral 7B** - –∏–¥–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
2. **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ Llama 2 13B** - –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—é–º–µ
3. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ** - –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–º–∏
4. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** - –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

## üöÄ –í–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ –ø–æ—Ç—è–Ω–µ—Ç –¥–∞–∂–µ –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏!

–° 32GB RAM –∏ AI –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å:
- –ù–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- –ë–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ (13B+ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
- –ë—ã—Å—Ç—Ä—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å NPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º

**–í–∞—à –Ω–æ—É—Ç–±—É–∫ - –∏–¥–µ–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π LLM!** üéâ
